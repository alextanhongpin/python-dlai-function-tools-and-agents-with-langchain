{
    "cells": [
        {
            "metadata": {},
            "id": "fc925562",
            "cell_type": "markdown",
            "source": "# LangChain Expression Language (LCEL)"
        },
        {
            "metadata": {
                "tags": [],
                "trusted": true,
                "height": 115
            },
            "id": "044db1b7-c18c-45d2-be7a-29f027c901e2",
            "cell_type": "code",
            "source": "import os\nimport openai\n\nfrom dotenv import load_dotenv, find_dotenv\n_ = load_dotenv(find_dotenv()) # read local .env file\nopenai.api_key = os.environ['OPENAI_API_KEY']",
            "execution_count": 1,
            "outputs": []
        },
        {
            "metadata": {
                "trusted": true,
                "height": 30
            },
            "id": "2de9d2bd-18de-44d5-81ac-5918e2106367",
            "cell_type": "code",
            "source": "#!pip install pydantic==1.10.8",
            "execution_count": 2,
            "outputs": []
        },
        {
            "metadata": {
                "trusted": true,
                "height": 64
            },
            "id": "fd55c0a0-ca4e-4311-a33c-fcebeb7d8b1e",
            "cell_type": "code",
            "source": "from langchain.prompts import ChatPromptTemplate\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.schema.output_parser import StrOutputParser",
            "execution_count": 3,
            "outputs": []
        },
        {
            "metadata": {},
            "id": "e99c432b-b2c9-497b-9912-c9ca4c1e3740",
            "cell_type": "markdown",
            "source": "## Simple Chain"
        },
        {
            "metadata": {
                "trusted": true,
                "height": 98
            },
            "id": "6a0be20d-0e00-478c-a844-017cad13af22",
            "cell_type": "code",
            "source": "prompt = ChatPromptTemplate.from_template(\n    \"tell me a short joke about {topic}\"\n)\nmodel = ChatOpenAI()\noutput_parser = StrOutputParser()",
            "execution_count": 4,
            "outputs": []
        },
        {
            "metadata": {
                "trusted": true,
                "height": 30
            },
            "id": "aedf1c1e-b697-47ce-9d81-eaec9192243b",
            "cell_type": "code",
            "source": "chain = prompt | model | output_parser",
            "execution_count": 5,
            "outputs": []
        },
        {
            "metadata": {
                "trusted": true,
                "height": 30
            },
            "id": "6df32028-d35f-4392-bb15-ddeec9ee09b5",
            "cell_type": "code",
            "source": "chain.invoke({\"topic\": \"bears\"})",
            "execution_count": 6,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 6,
                    "data": {
                        "text/plain": "\"Why don't bears wear shoes? \\n\\nBecause they have bear feet!\""
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "id": "d8ba33b5-2ae9-44d7-b023-18c903af571a",
            "cell_type": "markdown",
            "source": "## More complex chain\n\nAnd Runnable Map to supply user-provided inputs to the prompt."
        },
        {
            "metadata": {
                "trusted": true,
                "height": 47
            },
            "id": "d036bb8e-8ca7-4dbd-8103-f50a3c8c3af9",
            "cell_type": "code",
            "source": "from langchain.embeddings import OpenAIEmbeddings\nfrom langchain.vectorstores import DocArrayInMemorySearch",
            "execution_count": 7,
            "outputs": []
        },
        {
            "metadata": {
                "trusted": true,
                "height": 98
            },
            "id": "8955cff7-f1a2-4f94-ab5b-fcdda0859702",
            "cell_type": "code",
            "source": "vectorstore = DocArrayInMemorySearch.from_texts(\n    [\"harrison worked at kensho\", \"bears like to eat honey\"],\n    embedding=OpenAIEmbeddings()\n)\nretriever = vectorstore.as_retriever()",
            "execution_count": 8,
            "outputs": []
        },
        {
            "metadata": {
                "trusted": true,
                "height": 30
            },
            "id": "2df87934-1697-405c-b460-5e9bfd16c792",
            "cell_type": "code",
            "source": "retriever.get_relevant_documents(\"where did harrison work?\")",
            "execution_count": 9,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 9,
                    "data": {
                        "text/plain": "[Document(page_content='harrison worked at kensho'),\n Document(page_content='bears like to eat honey')]"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {
                "trusted": true,
                "height": 30
            },
            "id": "871cb26b-97b3-4f63-8bb3-523d3e6d117b",
            "cell_type": "code",
            "source": "retriever.get_relevant_documents(\"what do bears like to eat\")",
            "execution_count": 10,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 10,
                    "data": {
                        "text/plain": "[Document(page_content='bears like to eat honey'),\n Document(page_content='harrison worked at kensho')]"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {
                "trusted": true,
                "height": 130
            },
            "id": "127a7fb6-5821-4934-ab56-9e3300516c05",
            "cell_type": "code",
            "source": "template = \"\"\"Answer the question based only on the following context:\n{context}\n\nQuestion: {question}\n\"\"\"\nprompt = ChatPromptTemplate.from_template(template)",
            "execution_count": 11,
            "outputs": []
        },
        {
            "metadata": {
                "trusted": true,
                "height": 30
            },
            "id": "4ec01c56-731c-4e4f-a5f6-493fba953db0",
            "cell_type": "code",
            "source": "from langchain.schema.runnable import RunnableMap",
            "execution_count": 12,
            "outputs": []
        },
        {
            "metadata": {
                "trusted": true,
                "height": 96
            },
            "id": "a9ca6506-826f-4420-8f19-25dd4dbbc1dc",
            "cell_type": "code",
            "source": "chain = RunnableMap({\n    \"context\": lambda x: retriever.get_relevant_documents(x[\"question\"]),\n    \"question\": lambda x: x[\"question\"]\n}) | prompt | model | output_parser",
            "execution_count": 13,
            "outputs": []
        },
        {
            "metadata": {
                "trusted": true,
                "height": 30
            },
            "id": "707d1319-8840-4ed5-b4a4-a2a128799db6",
            "cell_type": "code",
            "source": "chain.invoke({\"question\": \"where did harrison work?\"})",
            "execution_count": 14,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 14,
                    "data": {
                        "text/plain": "'Harrison worked at Kensho.'"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {
                "trusted": true,
                "height": 96
            },
            "id": "05ec3727-4284-417e-9e23-eec0682eb002",
            "cell_type": "code",
            "source": "inputs = RunnableMap({\n    \"context\": lambda x: retriever.get_relevant_documents(x[\"question\"]),\n    \"question\": lambda x: x[\"question\"]\n})",
            "execution_count": 15,
            "outputs": []
        },
        {
            "metadata": {
                "trusted": true,
                "height": 30
            },
            "id": "4216c7ab-6d1b-4f2a-98dc-5d2ace23e3c2",
            "cell_type": "code",
            "source": "inputs.invoke({\"question\": \"where did harrison work?\"})",
            "execution_count": 16,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 16,
                    "data": {
                        "text/plain": "{'context': [Document(page_content='harrison worked at kensho'),\n  Document(page_content='bears like to eat honey')],\n 'question': 'where did harrison work?'}"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "id": "eec59c3b-33e7-437f-9b8b-b4652bc3b863",
            "cell_type": "markdown",
            "source": "## Bind\n\nand OpenAI Functions"
        },
        {
            "metadata": {
                "trusted": true,
                "height": 300
            },
            "id": "f3efed3b-6d4c-42a4-9692-0cc4596f530b",
            "cell_type": "code",
            "source": "functions = [\n    {\n      \"name\": \"weather_search\",\n      \"description\": \"Search for weather given an airport code\",\n      \"parameters\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"airport_code\": {\n            \"type\": \"string\",\n            \"description\": \"The airport code to get the weather for\"\n          },\n        },\n        \"required\": [\"airport_code\"]\n      }\n    }\n  ]",
            "execution_count": 17,
            "outputs": []
        },
        {
            "metadata": {
                "trusted": true,
                "height": 115
            },
            "id": "f8be4721-91d2-4ae6-8fdb-e91dc6ac1bc5",
            "cell_type": "code",
            "source": "prompt = ChatPromptTemplate.from_messages(\n    [\n        (\"human\", \"{input}\")\n    ]\n)\nmodel = ChatOpenAI(temperature=0).bind(functions=functions)",
            "execution_count": 18,
            "outputs": []
        },
        {
            "metadata": {
                "trusted": true,
                "height": 30
            },
            "id": "e61b095d-9934-41b8-a794-a9dd57e9c733",
            "cell_type": "code",
            "source": "runnable = prompt | model",
            "execution_count": 19,
            "outputs": []
        },
        {
            "metadata": {
                "trusted": true,
                "height": 30
            },
            "id": "a638efeb-b5ce-4aa4-8377-3e86597a03ab",
            "cell_type": "code",
            "source": "runnable.invoke({\"input\": \"what is the weather in sf\"})",
            "execution_count": 20,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 20,
                    "data": {
                        "text/plain": "AIMessage(content='', additional_kwargs={'function_call': {'name': 'weather_search', 'arguments': '{\\n  \"airport_code\": \"SFO\"\\n}'}})"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {
                "trusted": true,
                "height": 538
            },
            "id": "3a22faf5-ea24-48d2-b028-03733b548225",
            "cell_type": "code",
            "source": "functions = [\n    {\n      \"name\": \"weather_search\",\n      \"description\": \"Search for weather given an airport code\",\n      \"parameters\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"airport_code\": {\n            \"type\": \"string\",\n            \"description\": \"The airport code to get the weather for\"\n          },\n        },\n        \"required\": [\"airport_code\"]\n      }\n    },\n        {\n      \"name\": \"sports_search\",\n      \"description\": \"Search for news of recent sport events\",\n      \"parameters\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"team_name\": {\n            \"type\": \"string\",\n            \"description\": \"The sports team to search for\"\n          },\n        },\n        \"required\": [\"team_name\"]\n      }\n    }\n  ]",
            "execution_count": 21,
            "outputs": []
        },
        {
            "metadata": {
                "trusted": true,
                "height": 30
            },
            "id": "eb43b030-459f-47e8-a27d-96c2d70cdfef",
            "cell_type": "code",
            "source": "model = model.bind(functions=functions)",
            "execution_count": 22,
            "outputs": []
        },
        {
            "metadata": {
                "trusted": true,
                "height": 30
            },
            "id": "3ff03e0d-d6c6-4b47-815e-d7ea5b248567",
            "cell_type": "code",
            "source": "runnable = prompt | model",
            "execution_count": 23,
            "outputs": []
        },
        {
            "metadata": {
                "trusted": true,
                "height": 30
            },
            "id": "03855fa3-5e2f-4ab2-aba0-c2cd5423239e",
            "cell_type": "code",
            "source": "runnable.invoke({\"input\": \"how did the patriots do yesterday?\"})",
            "execution_count": 24,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 24,
                    "data": {
                        "text/plain": "AIMessage(content='', additional_kwargs={'function_call': {'name': 'sports_search', 'arguments': '{\\n  \"team_name\": \"patriots\"\\n}'}})"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "id": "bebc0c55-48c2-4105-90ec-7297553b8e6a",
            "cell_type": "markdown",
            "source": "## Fallbacks"
        },
        {
            "metadata": {
                "trusted": true,
                "height": 47
            },
            "id": "aa0b1ea2-7aef-4449-a553-426cb8c5aa30",
            "cell_type": "code",
            "source": "from langchain.llms import OpenAI\nimport json",
            "execution_count": 25,
            "outputs": []
        },
        {
            "metadata": {
                "trusted": true,
                "height": 115
            },
            "id": "17f90857-5625-4dba-bf3f-99432bd7f971",
            "cell_type": "code",
            "source": "simple_model = OpenAI(\n    temperature=0, \n    max_tokens=1000, \n    model=\"text-davinci-001\"\n)\nsimple_chain = simple_model | json.loads",
            "execution_count": 26,
            "outputs": []
        },
        {
            "metadata": {
                "trusted": true,
                "height": 45
            },
            "id": "441928c5-8712-45c5-bfdf-6f51634198a7",
            "cell_type": "code",
            "source": "challenge = \"write three poems in a json blob, where each poem is a json blob of a title, author, and first line\"",
            "execution_count": 27,
            "outputs": []
        },
        {
            "metadata": {
                "trusted": true,
                "height": 30
            },
            "id": "0739e85f-8497-4471-8ec9-17e958d80771",
            "cell_type": "code",
            "source": "simple_model.invoke(challenge)",
            "execution_count": 28,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 28,
                    "data": {
                        "text/plain": "'\\n\\n[\"The Waste Land\",\"T.S. Eliot\",\"April is the cruelest month, breeding lilacs out of the dead land\"]\\n\\n[\"The Raven\",\"Edgar Allan Poe\",\"Once upon a midnight dreary, while I pondered, weak and weary\"]\\n\\n[\"Ode to a Nightingale\",\"John Keats\",\"Thou still unravish\\'d bride of quietness, Thou foster-child of silence and slow time\"]'"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "id": "3a20d15c-dc8a-4b6d-a423-a5f814425219",
            "cell_type": "markdown",
            "source": "Note: The next line is expected to fail."
        },
        {
            "metadata": {
                "trusted": true,
                "height": 30
            },
            "id": "2a5e8492-0927-4a3a-b939-947826246330",
            "cell_type": "code",
            "source": "simple_chain.invoke(challenge)",
            "execution_count": 29,
            "outputs": [
                {
                    "output_type": "error",
                    "ename": "JSONDecodeError",
                    "evalue": "Extra data: line 5 column 1 (char 103)",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msimple_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchallenge\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/langchain/schema/runnable/base.py:1113\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1112\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps):\n\u001b[0;32m-> 1113\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1115\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# mark each step as a child run\u001b[39;49;00m\n\u001b[1;32m   1116\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1117\u001b[0m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseq:step:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1118\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1119\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
                        "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/langchain/schema/runnable/base.py:2163\u001b[0m, in \u001b[0;36mRunnableLambda.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2161\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Invoke this runnable synchronously.\"\"\"\u001b[39;00m\n\u001b[1;32m   2162\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunc\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 2163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invoke\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2165\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2166\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2167\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2169\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   2170\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot invoke a coroutine function synchronously.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2171\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse `ainvoke` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2172\u001b[0m     )\n",
                        "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/langchain/schema/runnable/base.py:633\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[0;34m(self, func, input, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m    626\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[1;32m    627\u001b[0m     dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    629\u001b[0m     run_type\u001b[38;5;241m=\u001b[39mrun_type,\n\u001b[1;32m    630\u001b[0m     name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    631\u001b[0m )\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 633\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    637\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
                        "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/langchain/schema/runnable/config.py:173\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    172\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[0;32m--> 173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/langchain/schema/runnable/base.py:2096\u001b[0m, in \u001b[0;36mRunnableLambda._invoke\u001b[0;34m(self, input, run_manager, config)\u001b[0m\n\u001b[1;32m   2090\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_invoke\u001b[39m(\n\u001b[1;32m   2091\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2092\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[1;32m   2093\u001b[0m     run_manager: CallbackManagerForChainRun,\n\u001b[1;32m   2094\u001b[0m     config: RunnableConfig,\n\u001b[1;32m   2095\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[0;32m-> 2096\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2097\u001b[0m     \u001b[38;5;66;03m# If the output is a runnable, invoke it\u001b[39;00m\n\u001b[1;32m   2098\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, Runnable):\n",
                        "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/langchain/schema/runnable/config.py:173\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    172\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[0;32m--> 173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m/usr/local/lib/python3.9/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
                        "File \u001b[0;32m/usr/local/lib/python3.9/json/decoder.py:340\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n\u001b[0;32m--> 340\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtra data\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, end)\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
                        "\u001b[0;31mJSONDecodeError\u001b[0m: Extra data: line 5 column 1 (char 103)"
                    ]
                }
            ]
        },
        {
            "metadata": {
                "trusted": true,
                "height": 47
            },
            "id": "6814143b-4a35-4d29-bd32-ba461274bcbf",
            "cell_type": "code",
            "source": "model = ChatOpenAI(temperature=0)\nchain = model | StrOutputParser() | json.loads",
            "execution_count": 30,
            "outputs": []
        },
        {
            "metadata": {
                "trusted": true,
                "height": 30
            },
            "id": "f55f04cf-0217-4106-b41f-0e0661d12c27",
            "cell_type": "code",
            "source": "chain.invoke(challenge)",
            "execution_count": 31,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 31,
                    "data": {
                        "text/plain": "{'poem1': {'title': 'Whispers of the Wind',\n  'author': 'Emily Rivers',\n  'first_line': 'Softly it comes, the whisper of the wind'},\n 'poem2': {'title': 'Silent Serenade',\n  'author': 'Jacob Moore',\n  'first_line': 'In the stillness of night, a silent serenade'},\n 'poem3': {'title': 'Dancing Shadows',\n  'author': 'Sophia Anderson',\n  'first_line': 'Shadows dance upon the moonlit floor'}}"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {
                "trusted": true,
                "height": 30
            },
            "id": "b5d3f035-b18d-4cba-854d-a43ef8554e48",
            "cell_type": "code",
            "source": "final_chain = simple_chain.with_fallbacks([chain])",
            "execution_count": 32,
            "outputs": []
        },
        {
            "metadata": {
                "trusted": true,
                "height": 30
            },
            "id": "9a09fe6a-548c-412d-9468-9efe2b49f7c9",
            "cell_type": "code",
            "source": "final_chain.invoke(challenge)",
            "execution_count": 33,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 33,
                    "data": {
                        "text/plain": "{'poem1': {'title': 'Whispers of the Wind',\n  'author': 'Emily Rivers',\n  'first_line': 'In the stillness of night, whispers of the wind'},\n 'poem2': {'title': 'Silent Tears',\n  'author': 'Jacob Anderson',\n  'first_line': 'Silent tears fall, unseen and unheard'},\n 'poem3': {'title': 'Dancing Shadows',\n  'author': 'Sophia Lee',\n  'first_line': 'Dancing shadows on the wall, a silent ballet'}}"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "id": "3fcfdda0-3db2-4073-a647-f2d62c460349",
            "cell_type": "markdown",
            "source": "## Interface"
        },
        {
            "metadata": {
                "trusted": true,
                "height": 132
            },
            "id": "33b3b27f-b5a0-4db5-a1b0-20754437a47e",
            "cell_type": "code",
            "source": "prompt = ChatPromptTemplate.from_template(\n    \"Tell me a short joke about {topic}\"\n)\nmodel = ChatOpenAI()\noutput_parser = StrOutputParser()\n\nchain = prompt | model | output_parser",
            "execution_count": 34,
            "outputs": []
        },
        {
            "metadata": {
                "trusted": true,
                "height": 30
            },
            "id": "48c8cabf-ea55-4448-b070-3ec22942c559",
            "cell_type": "code",
            "source": "chain.invoke({\"topic\": \"bears\"})",
            "execution_count": 35,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 35,
                    "data": {
                        "text/plain": "\"Why don't bears use cell phones?\\n\\nBecause they can't bear to have their calls dropped!\""
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {
                "trusted": true,
                "height": 30
            },
            "id": "cc58bdb4-a896-46ba-90c4-1b333245229a",
            "cell_type": "code",
            "source": "chain.batch([{\"topic\": \"bears\"}, {\"topic\": \"frogs\"}])",
            "execution_count": 36,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 36,
                    "data": {
                        "text/plain": "[\"Sure, here's a short bear joke: \\n\\nWhy don't bears wear shoes?\\n\\nBecause they have bear feet!\",\n 'Why did the frog go to the hospital? \\n\\nBecause he needed a \"ribbit\" operation!']"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {
                "trusted": true,
                "height": 47
            },
            "id": "8a069d61-0a67-4368-b7c4-367262267bb8",
            "cell_type": "code",
            "source": "for t in chain.stream({\"topic\": \"bears\"}):\n    print(t)",
            "execution_count": null,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: HTTP code 500 from API (500 error\n).\nRetrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: HTTP code 500 from API (500 error\n).\nRetrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: HTTP code 500 from API (500 error\n).\nRetrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised APIError: HTTP code 500 from API (500 error\n).\n",
                    "name": "stderr"
                }
            ]
        },
        {
            "metadata": {
                "trusted": true,
                "height": 47
            },
            "id": "2315b43f-c7e1-4f7b-9595-4cabdc019dea",
            "cell_type": "code",
            "source": "response = await chain.ainvoke({\"topic\": \"bears\"})\nresponse",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "trusted": true,
                "height": 30
            },
            "id": "f3082379-f75e-4a74-bee5-c18ddc5ac4dc",
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "trusted": true,
                "height": 30
            },
            "id": "adccca48-787e-4219-af82-f18e6408182b",
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "trusted": true,
                "height": 30
            },
            "id": "5c816827-e5b7-480a-826b-0ca715faca3c",
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "trusted": true,
                "height": 30
            },
            "id": "15e6d608-c205-4141-bab8-0304dd910978",
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "trusted": true,
                "height": 30
            },
            "id": "abfc490d-090d-4e1c-b8ee-bf40ec4da4c3",
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "trusted": true,
                "height": 30
            },
            "id": "5fe48ff0-fd84-4c9e-8069-02117d57f7f0",
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3 (ipykernel)",
            "language": "python"
        },
        "language_info": {
            "name": "python",
            "version": "3.9.18",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
